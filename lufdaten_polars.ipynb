{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use uv venv. Need to uv pip install polars-lts-cpu on older machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import duckdb\n",
    "import requests\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can use awk -F';' 'NR==1 || ($5 >= -3 && $5 <= -2)' data/2023-12_sds011.csv > data/output.csv\n",
    "\n",
    "but it doesn't seem any faster than using polars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2024, 2025, 1)\n",
    "month_nums = range(1, 13, 1)\n",
    "month_strs = [f'0{str(mon)}' if mon < 10 else str(mon) for mon in month_nums]\n",
    "yr_mon_list = []\n",
    "for year in years:\n",
    "    for m in month_strs:\n",
    "        yr_mon_list.append(f'{year}-{m}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(yr_mon_list[0])\n",
    "yr_mon_list[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unz_del(yr_mon: str, sensor_type: str = 'bme280'):\n",
    "    '''\n",
    "    Download and unzip a csv file for the year \\ month and sensor type specified.\n",
    "    Delete the original zip file after extraction.\n",
    "\n",
    "    '''\n",
    "       \n",
    "    # URL of the ZIP file to download\n",
    "    zip_url = f'https://archive.sensor.community/csv_per_month/{yr_mon}/{yr_mon}_{sensor_type}.zip'\n",
    "\n",
    "    # Path where the ZIP file will be saved temporarily\n",
    "    # data folder\n",
    "    datfolder = 'data'\n",
    "    zip_path = f'{datfolder}/temp.zip'\n",
    "\n",
    "    try:\n",
    "        # Download the ZIP file\n",
    "        print(f\"Downloading ZIP file from {zip_url}...\")\n",
    "        response = requests.get(zip_url)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the response was an HTTP error\n",
    "\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Download complete.\")\n",
    "        extracted_files = []\n",
    "        # Unzip the archive\n",
    "        print(\"Extracting ZIP file...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('data')\n",
    "        print(\"Extraction complete.\")\n",
    "        extracted_files = zip_ref.namelist()[0]\n",
    "\n",
    "        if os.path.exists(zip_path):\n",
    "            os.remove(zip_path)\n",
    "            print(\"Original ZIP file deleted.\")\n",
    "            return extracted_files\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred during the download: {e}\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"The downloaded file is not a valid ZIP file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2024-02/2024-02_bme280.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2024-02_bme280.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unz_del('2024-02', 'bme280')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bme_sensor_data_fact_df(csv_file: str) -> pl.DataFrame:\n",
    "    '''\n",
    "    Read a bme280 csv file, filter for lep area, calculate hourly mean values\n",
    "    for pressure, temperature, humidity\n",
    "    clean it and write it to a new csv file\n",
    "    '''\n",
    "    path = f'data/{csv_file}'\n",
    "    try:\n",
    "        raw_df = pl.scan_csv(path,\n",
    "            has_header=True,\n",
    "            separator=';',\n",
    "            null_values = [' ', 'unavailable', 'unknown', 'b'],\n",
    "            schema = {'sensor_id': pl.Int64,\n",
    "                      'sensor_type': pl.Utf8,\n",
    "                      'location': pl.Int64,\n",
    "                      'lat': pl.Float64,\n",
    "                      'lon': pl.Float64,\n",
    "                      'timestamp': pl.Datetime,\n",
    "                      'pressure': pl.Float64,\n",
    "                      'altitude': pl.Float64,\n",
    "                      'pressure_sealevel': pl.Float64,\n",
    "                      'temperature': pl.Float64,\n",
    "                      'humidity': pl.Float64},\n",
    "            ignore_errors=True)\n",
    "        \n",
    "        sensor_data_fact_df = (\n",
    "            raw_df\n",
    "             .filter([pl.col('lon').is_between(-3, -2.18), pl.col('lat').is_between(51.2, 51.6)])\n",
    "             .select(['sensor_id', 'lat', 'lon', 'timestamp', 'pressure', 'temperature', 'humidity'])\n",
    "             .sort(by = [pl.col('sensor_id'), pl.col('timestamp')])\n",
    "             .group_by_dynamic('timestamp', every = \"1h\", group_by = 'sensor_id')\n",
    "             .agg([pl.col('pressure').mean(),\n",
    "                pl.col('temperature').mean(),\n",
    "                pl.col('humidity').mean(),\n",
    "                pl.col('lat').first().alias(\"lat\"),\n",
    "                pl.col('lon').first().alias(\"lon\")\n",
    "                    ])\n",
    "             ).collect()\n",
    "\n",
    "        thedate = (sensor_data_fact_df\n",
    "        .head(1)\n",
    "        .select(pl.col('timestamp'))\n",
    "        .to_series(0)\n",
    "        )[0]\n",
    "        clean_file_out_path = f'data/cleaned/{str(thedate.year)}-{str(thedate.month)}_bme280_clean.csv'\n",
    "        sensor_data_fact_df.write_csv(clean_file_out_path)\n",
    "        os.remove(path)\n",
    "        \n",
    "        return sensor_data_fact_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sensor_data_fact_df(csv_file: str) -> pl.DataFrame:\n",
    "    path = f'data/{csv_file}'\n",
    "    try:\n",
    "        raw_df = pl.scan_csv(path,\n",
    "            null_values = [' ', 'unavailable', 'unknown', 'b'],\n",
    "            # columns = ['sensor_id', 'location', 'lat', 'lon', 'timestamp', 'P1', 'P2'],\n",
    "            separator=';',\n",
    "            ignore_errors = True,\n",
    "            schema = {\n",
    "                            'sensor_id': pl.Int64,\n",
    "                            'sensor_type': pl.Utf8,\n",
    "                            'location': pl.Utf8,\n",
    "                            'lat':pl.Float64,\n",
    "                            'lon':pl.Float64,\n",
    "                            'timestamp':pl.Datetime,\n",
    "                            'P1':pl.Float64,\n",
    "                            'durP1': pl.Float64,\n",
    "                            'ratioP1': pl.Float64,\n",
    "                            'P2':pl.Float64,\n",
    "                            'durP2': pl.Float64,\n",
    "                            'ratioP2': pl.Float64,\n",
    "                        },\n",
    "            try_parse_dates = True#,\n",
    "            # n_rows=1000\n",
    "            )\n",
    "        \n",
    "        sensor_data_fact_df = (\n",
    "            raw_df\n",
    "            .filter([pl.col('lon').is_between(-3, -2.18),\n",
    "                     pl.col('lat').is_between(51.2, 51.6)])\n",
    "                     .select(['sensor_id', 'lat', 'lon', 'timestamp', 'P1', 'P2'])\n",
    "                    .sort(by = [pl.col('sensor_id'), pl.col('timestamp')])\n",
    "                    .group_by_dynamic('timestamp', every = \"1h\", by = 'sensor_id')\n",
    "                    .agg([\n",
    "                        pl.col('P1').mean().alias(\"pm10\"),\n",
    "                        pl.col('P2').mean().alias(\"pm2.5\"),\n",
    "                        pl.col('lat').first().alias(\"lat\"),\n",
    "                        pl.col('lon').first().alias(\"lon\")\n",
    "                    ])                    \n",
    "            ).collect()\n",
    "\n",
    "        thedate = (sensor_data_fact_df\n",
    "        .head(1)\n",
    "        .select(pl.col('timestamp'))\n",
    "        .to_series(0)\n",
    "        )[0]\n",
    "        clean_file_out_path = f'data/cleaned/{str(thedate.year)}-{str(thedate.month)}_SDS011_clean.csv'\n",
    "        sensor_data_fact_df.write_csv(clean_file_out_path)\n",
    "        os.remove(path)\n",
    "        \n",
    "        return sensor_data_fact_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(g, f):\n",
    "    def h(x):\n",
    "        return g(f(x))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = compose(make_bme_sensor_data_fact_df, unz_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2023-01/2023-01_bme280.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n"
     ]
    }
   ],
   "source": [
    "raw_df = comp('2023-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2024-01/2024-01_bme280.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n",
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2024-02/2024-02_bme280.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n",
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2024-03/2024-03_bme280.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n",
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2024-04/2024-04_bme280.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n",
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2024-05/2024-05_bme280.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n",
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2024-06/2024-06_bme280.zip...\n",
      "An error occurred during the download: 404 Client Error: Not Found for url: https://archive.sensor.community/csv_per_month/2024-06/2024-06_bme280.zip\n",
      "An error occurred: No such file or directory (os error 2): data/None\n"
     ]
    }
   ],
   "source": [
    "lep_bme = [comp(yr_mon) for yr_mon in yr_mon_list[0:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "misslist = ['2020-02', '2021-02', '2021-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2020-02/2020-02_sds011.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n",
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2021-02/2021-02_sds011.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n",
      "Downloading ZIP file from https://archive.sensor.community/csv_per_month/2021-03/2021-03_sds011.zip...\n",
      "Download complete.\n",
      "Extracting ZIP file...\n",
      "Extraction complete.\n",
      "Original ZIP file deleted.\n"
     ]
    }
   ],
   "source": [
    "df_miss = [comp(yr_mon) for yr_mon in misslist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123398, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('data/cleaned')\n",
    "lazy_df_list = []\n",
    "for file in files:\n",
    "    lazy_df = pl.read_csv(f'data/cleaned/{file}',   try_parse_dates=True)\n",
    "    lazy_df_list.append(lazy_df)\n",
    "\n",
    "complete_df = (\n",
    "    pl.concat(lazy_df_list)\n",
    ")\n",
    "\n",
    "complete_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_bme_280_df = (complete_df\n",
    "                  .filter(pl.col('timestamp') >= pl.datetime(2022, 1, 1))\n",
    "                  .with_columns([pl.when(pl.col('temperature') < -10).then(None).otherwise(pl.col('temperature')).round(4).alias('temperature'),\n",
    "                                 pl.col(['pressure']).mul(0.01).round(4).alias('pressure'),\n",
    "                                 pl.col(['humidity']).round(4).alias('humidity')])\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 90590\n",
      "Columns: 7\n",
      "$ sensor_id            <i64> 48882, 48882, 48882, 48882, 48882, 48882, 48882, 48882, 48882, 48882\n",
      "$ timestamp   <datetime[μs]> 2023-06-06 17:00:00, 2023-06-06 18:00:00, 2023-06-06 19:00:00, 2023-06-06 20:00:00, 2023-06-06 21:00:00, 2023-06-06 22:00:00, 2023-06-06 23:00:00, 2023-06-07 00:00:00, 2023-06-07 01:00:00, 2023-06-07 02:00:00\n",
      "$ pressure             <f64> 1011.345, 1011.4622, 1011.5312, 1011.8512, 1012.0571, 1012.0832, 1012.1351, 1011.8919, 1011.6651, 1011.3792\n",
      "$ temperature          <f64> 15.8185, 14.686, 13.8513, 13.43, 12.6448, 11.6975, 10.6024, 9.7444, 9.1154, 8.8117\n",
      "$ humidity             <f64> 58.634, 61.4704, 64.2175, 67.3016, 73.818, 72.8004, 77.4236, 80.4672, 83.5163, 88.0358\n",
      "$ lat                  <f64> 51.406, 51.406, 51.406, 51.406, 51.406, 51.406, 51.406, 51.406, 51.406, 51.406\n",
      "$ lon                  <f64> -2.402, -2.402, -2.402, -2.402, -2.402, -2.402, -2.402, -2.402, -2.402, -2.402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ods_bme_280_df.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>sensor_id</th><th>timestamp</th><th>pressure</th><th>temperature</th><th>humidity</th><th>lat</th><th>lon</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>90590.0</td><td>&quot;90590&quot;</td><td>90590.0</td><td>87666.0</td><td>90590.0</td><td>90590.0</td><td>90590.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>2924.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>62800.49299</td><td>&quot;2023-04-23 21:…</td><td>997.270291</td><td>14.622548</td><td>NaN</td><td>51.408203</td><td>-2.572177</td></tr><tr><td>&quot;std&quot;</td><td>10673.291443</td><td>null</td><td>70.504578</td><td>7.008122</td><td>NaN</td><td>0.056772</td><td>0.214772</td></tr><tr><td>&quot;min&quot;</td><td>32911.0</td><td>&quot;2022-01-01 00:…</td><td>578.6294</td><td>-9.62</td><td>0.0</td><td>51.258</td><td>-2.906</td></tr><tr><td>&quot;25%&quot;</td><td>53889.0</td><td>&quot;2022-09-26 05:…</td><td>1001.2294</td><td>9.7928</td><td>56.8796</td><td>51.356</td><td>-2.61</td></tr><tr><td>&quot;50%&quot;</td><td>69351.0</td><td>&quot;2023-05-28 09:…</td><td>1010.3998</td><td>13.7217</td><td>82.4515</td><td>51.406</td><td>-2.606</td></tr><tr><td>&quot;75%&quot;</td><td>70370.0</td><td>&quot;2023-11-17 00:…</td><td>1018.427</td><td>19.3863</td><td>100.0</td><td>51.446</td><td>-2.402</td></tr><tr><td>&quot;max&quot;</td><td>82887.0</td><td>&quot;2024-05-31 23:…</td><td>1249.6848</td><td>51.5779</td><td>100.0</td><td>51.587451</td><td>-2.183243</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 8)\n",
       "┌────────────┬────────────┬────────────┬────────────┬───────────┬──────────┬───────────┬───────────┐\n",
       "│ statistic  ┆ sensor_id  ┆ timestamp  ┆ pressure   ┆ temperatu ┆ humidity ┆ lat       ┆ lon       │\n",
       "│ ---        ┆ ---        ┆ ---        ┆ ---        ┆ re        ┆ ---      ┆ ---       ┆ ---       │\n",
       "│ str        ┆ f64        ┆ str        ┆ f64        ┆ ---       ┆ f64      ┆ f64       ┆ f64       │\n",
       "│            ┆            ┆            ┆            ┆ f64       ┆          ┆           ┆           │\n",
       "╞════════════╪════════════╪════════════╪════════════╪═══════════╪══════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 90590.0    ┆ 90590      ┆ 90590.0    ┆ 87666.0   ┆ 90590.0  ┆ 90590.0   ┆ 90590.0   │\n",
       "│ null_count ┆ 0.0        ┆ 0          ┆ 0.0        ┆ 2924.0    ┆ 0.0      ┆ 0.0       ┆ 0.0       │\n",
       "│ mean       ┆ 62800.4929 ┆ 2023-04-23 ┆ 997.270291 ┆ 14.622548 ┆ NaN      ┆ 51.408203 ┆ -2.572177 │\n",
       "│            ┆ 9          ┆ 21:09:46.7 ┆            ┆           ┆          ┆           ┆           │\n",
       "│            ┆            ┆ 13765      ┆            ┆           ┆          ┆           ┆           │\n",
       "│ std        ┆ 10673.2914 ┆ null       ┆ 70.504578  ┆ 7.008122  ┆ NaN      ┆ 0.056772  ┆ 0.214772  │\n",
       "│            ┆ 43         ┆            ┆            ┆           ┆          ┆           ┆           │\n",
       "│ min        ┆ 32911.0    ┆ 2022-01-01 ┆ 578.6294   ┆ -9.62     ┆ 0.0      ┆ 51.258    ┆ -2.906    │\n",
       "│            ┆            ┆ 00:00:00   ┆            ┆           ┆          ┆           ┆           │\n",
       "│ 25%        ┆ 53889.0    ┆ 2022-09-26 ┆ 1001.2294  ┆ 9.7928    ┆ 56.8796  ┆ 51.356    ┆ -2.61     │\n",
       "│            ┆            ┆ 05:00:00   ┆            ┆           ┆          ┆           ┆           │\n",
       "│ 50%        ┆ 69351.0    ┆ 2023-05-28 ┆ 1010.3998  ┆ 13.7217   ┆ 82.4515  ┆ 51.406    ┆ -2.606    │\n",
       "│            ┆            ┆ 09:00:00   ┆            ┆           ┆          ┆           ┆           │\n",
       "│ 75%        ┆ 70370.0    ┆ 2023-11-17 ┆ 1018.427   ┆ 19.3863   ┆ 100.0    ┆ 51.446    ┆ -2.402    │\n",
       "│            ┆            ┆ 00:00:00   ┆            ┆           ┆          ┆           ┆           │\n",
       "│ max        ┆ 82887.0    ┆ 2024-05-31 ┆ 1249.6848  ┆ 51.5779   ┆ 100.0    ┆ 51.587451 ┆ -2.183243 │\n",
       "│            ┆            ┆ 23:00:00   ┆            ┆           ┆          ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴────────────┴───────────┴──────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ods_bme_280_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_bme_280_df.write_parquet('data/cleaned/bme_sensors.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_bme_280_df.write_csv('data/cleaned/bme_sensors.csv', null_value=\"\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df = pl.read_csv('data/sensor_df_complete.csv', try_parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59165,\n",
       " 56923,\n",
       " 54309,\n",
       " 67665,\n",
       " 47083,\n",
       " 17459,\n",
       " 22979,\n",
       " 56405,\n",
       " 3040,\n",
       " 47271,\n",
       " 23646,\n",
       " 49233,\n",
       " 57227,\n",
       " 5193,\n",
       " 34954,\n",
       " 47265,\n",
       " 65090,\n",
       " 49227,\n",
       " 7685,\n",
       " 49480,\n",
       " 53949,\n",
       " 65084,\n",
       " 66966,\n",
       " 65379,\n",
       " 66987,\n",
       " 20842,\n",
       " 17314,\n",
       " 51770,\n",
       " 39950,\n",
       " 53890,\n",
       " 72367,\n",
       " 70369,\n",
       " 31188,\n",
       " 66963,\n",
       " 12711,\n",
       " 66972,\n",
       " 56379,\n",
       " 68589,\n",
       " 26922,\n",
       " 23644,\n",
       " 65049,\n",
       " 39254,\n",
       " 45804,\n",
       " 57043,\n",
       " 78947,\n",
       " 47093,\n",
       " 65073,\n",
       " 8582,\n",
       " 67568,\n",
       " 33862,\n",
       " 54813,\n",
       " 24147,\n",
       " 11068,\n",
       " 14787,\n",
       " 47263,\n",
       " 17502,\n",
       " 50038,\n",
       " 26044,\n",
       " 51720,\n",
       " 54757,\n",
       " 56469,\n",
       " 48987,\n",
       " 35068,\n",
       " 71552,\n",
       " 34288,\n",
       " 49231,\n",
       " 65088,\n",
       " 48859,\n",
       " 21989,\n",
       " 56341,\n",
       " 32984,\n",
       " 66970,\n",
       " 65047,\n",
       " 10491,\n",
       " 62915,\n",
       " 65407,\n",
       " 47085,\n",
       " 56255,\n",
       " 67655,\n",
       " 54019,\n",
       " 17318,\n",
       " 36581,\n",
       " 51768,\n",
       " 39570,\n",
       " 38525,\n",
       " 66979,\n",
       " 70153,\n",
       " 65086,\n",
       " 40571,\n",
       " 50765,\n",
       " 70326,\n",
       " 69775,\n",
       " 70424,\n",
       " 69513,\n",
       " 54466,\n",
       " 7675,\n",
       " 51072,\n",
       " 65080,\n",
       " 65077,\n",
       " 17506,\n",
       " 60492,\n",
       " 38362,\n",
       " 59364,\n",
       " 47836,\n",
       " 29880,\n",
       " 10179,\n",
       " 35382,\n",
       " 51748,\n",
       " 39836,\n",
       " 65405,\n",
       " 59605,\n",
       " 50036,\n",
       " 48881,\n",
       " 8741,\n",
       " 59617,\n",
       " 66974]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_sensor_df = (\n",
    "    sensor_df\n",
    "    .group_by('sensor_id')\n",
    "    .agg([pl.col('lat').first().alias('latitude'),\n",
    "          pl.col('lon').first().alias('longitude')])\n",
    "    .filter([pl.col('longitude').is_between(-3, -2.18),\n",
    "             pl.col('latitude').is_between(51.2, 51.6)])\n",
    ")\n",
    "lep_sensors = (dim_sensor_df\n",
    "               .select('sensor_id')\n",
    "               .to_series())\n",
    "lep_sensors_list = list(lep_sensors)\n",
    "lep_sensors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sensor_hr_df = (\n",
    "    sensor_df\n",
    "    .drop(['lat', 'lon'])\n",
    "    .sort(['sensor_id', 'timestamp'])\n",
    "    .filter(pl.col('sensor_id').is_in(lep_sensors_list))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1052092\n",
      "Columns: 4\n",
      "$ sensor_id          <i64> 3040, 3040, 3040, 3040, 3040, 3040, 3040, 3040, 3040, 3040\n",
      "$ timestamp <datetime[μs]> 2020-01-01 00:00:00, 2020-01-01 01:00:00, 2020-01-01 02:00:00, 2020-01-01 03:00:00, 2020-01-01 04:00:00, 2020-01-01 05:00:00, 2020-01-01 06:00:00, 2020-01-01 07:00:00, 2020-01-01 08:00:00, 2020-01-01 09:00:00\n",
      "$ pm10               <f64> 5.729583333333333, 5.000416666666666, 2.8571999999999993, 2.11625, 1.8737500000000002, 1.5132000000000003, 1.3462500000000004, 2.592, 0.8758333333333334, 1.3576000000000001\n",
      "$ pm2.5              <f64> 4.085, 3.2174999999999994, 1.9967999999999995, 1.1295833333333334, 1.3020833333333333, 1.1440000000000001, 1.1170833333333332, 1.962, 0.75, 0.9531999999999998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_sensor_hr_df.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sensor_day_df = (fact_sensor_hr_df\n",
    "                      .group_by_dynamic('timestamp', every='1d', by = 'sensor_id', closed='left')\n",
    "                      .agg([pl.col('pm10').mean(),\n",
    "                            pl.col('pm2.5').mean()])\n",
    "                        .filter(pl.col('pm10').is_not_nan(),\n",
    "                                pl.col('pm2.5').is_not_nan())\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 44983\n",
      "Columns: 4\n",
      "$ sensor_id          <i64> 3040, 3040, 3040, 3040, 3040, 3040, 3040, 3040, 3040, 3040\n",
      "$ timestamp <datetime[μs]> 2020-01-01 00:00:00, 2020-01-02 00:00:00, 2020-01-03 00:00:00, 2020-01-04 00:00:00, 2020-01-05 00:00:00, 2020-01-06 00:00:00, 2020-01-07 00:00:00, 2020-01-08 00:00:00, 2020-01-19 00:00:00, 2020-01-20 00:00:00\n",
      "$ pm10               <f64> 1.777557216183575, 1.2170368620037806, 1.0376101751207731, 0.8214650664251207, 0.8532078947368423, 1.5582531400966184, 0.5171283089042601, 1.3677803402646505, 1.1649741715399609, 0.7742836940836941\n",
      "$ pm2.5              <f64> 1.2739747886473427, 0.7568890044108381, 0.565838979468599, 0.5262321859903384, 0.5102237639553429, 0.7873081521739129, 0.3906180816315327, 0.7129304032766228, 1.0033465886939572, 0.7441821067821067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_sensor_day_df.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_sensor_df.write_csv('data/dim_sensor_df.csv')\n",
    "fact_sensor_hr_df.write_csv('data/fact_sensor_hr_df.csv')\n",
    "fact_sensor_day_df.write_csv('data/fact_sensor_day_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 149\n",
      "Columns: 3\n",
      "$ sensor_id <i64> 59165, 54309, 56923, 3040, 45386, 68597, 17459, 56405, 67665, 22979\n",
      "$ latitude  <f64> 51.5, 51.5, 51.5, 51.40000000000466, 51.89999999999797, 51.0, 51.5, 51.40000000001312, 51.5, 51.40000000000085\n",
      "$ longitude <f64> -2.599999999999943, -2.5, -2.8000000000009573, -2.5999999999999828, -2.8000000000001135, -2.7999999999999807, -2.5999999999999526, -2.5999999999993295, -2.5999999999993535, -2.599999999999956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_sensor_df.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data_fact_df = make_sensor_data_fact_df(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (34_897, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sensor_id</th><th>timestamp</th><th>pm10</th><th>pm2.5</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>7675</td><td>2023-01-01 00:00:00</td><td>8.8</td><td>3.0</td></tr><tr><td>7675</td><td>2023-01-01 01:00:00</td><td>14.5</td><td>3.7</td></tr><tr><td>7675</td><td>2023-01-01 02:00:00</td><td>16.6</td><td>4.2</td></tr><tr><td>7675</td><td>2023-01-01 03:00:00</td><td>18.7</td><td>4.1</td></tr><tr><td>7675</td><td>2023-01-01 04:00:00</td><td>15.1</td><td>3.5</td></tr><tr><td>7675</td><td>2023-01-01 05:00:00</td><td>13.3</td><td>3.1</td></tr><tr><td>7675</td><td>2023-01-01 06:00:00</td><td>17.8</td><td>3.7</td></tr><tr><td>7675</td><td>2023-01-01 07:00:00</td><td>20.1</td><td>4.3</td></tr><tr><td>7675</td><td>2023-01-01 08:00:00</td><td>20.6</td><td>4.5</td></tr><tr><td>7675</td><td>2023-01-01 09:00:00</td><td>26.5</td><td>5.5</td></tr><tr><td>7675</td><td>2023-01-01 10:00:00</td><td>24.4</td><td>5.3</td></tr><tr><td>7675</td><td>2023-01-01 11:00:00</td><td>24.6</td><td>5.6</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>77709</td><td>2023-01-23 08:00:00</td><td>11.4</td><td>5.6</td></tr><tr><td>77709</td><td>2023-01-23 09:00:00</td><td>18.7</td><td>6.8</td></tr><tr><td>77709</td><td>2023-01-23 10:00:00</td><td>16.8</td><td>7.0</td></tr><tr><td>77709</td><td>2023-01-23 11:00:00</td><td>16.6</td><td>8.1</td></tr><tr><td>77709</td><td>2023-01-23 12:00:00</td><td>15.2</td><td>5.6</td></tr><tr><td>77709</td><td>2023-01-23 13:00:00</td><td>8.9</td><td>3.3</td></tr><tr><td>77709</td><td>2023-01-23 14:00:00</td><td>5.5</td><td>3.0</td></tr><tr><td>77709</td><td>2023-01-23 15:00:00</td><td>6.5</td><td>2.8</td></tr><tr><td>77709</td><td>2023-01-23 16:00:00</td><td>6.1</td><td>3.1</td></tr><tr><td>77709</td><td>2023-01-23 17:00:00</td><td>13.4</td><td>6.7</td></tr><tr><td>77709</td><td>2023-01-23 18:00:00</td><td>15.5</td><td>8.4</td></tr><tr><td>77709</td><td>2023-01-23 19:00:00</td><td>20.5</td><td>10.4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (34_897, 4)\n",
       "┌───────────┬─────────────────────┬──────┬───────┐\n",
       "│ sensor_id ┆ timestamp           ┆ pm10 ┆ pm2.5 │\n",
       "│ ---       ┆ ---                 ┆ ---  ┆ ---   │\n",
       "│ i64       ┆ datetime[μs]        ┆ f64  ┆ f64   │\n",
       "╞═══════════╪═════════════════════╪══════╪═══════╡\n",
       "│ 7675      ┆ 2023-01-01 00:00:00 ┆ 8.8  ┆ 3.0   │\n",
       "│ 7675      ┆ 2023-01-01 01:00:00 ┆ 14.5 ┆ 3.7   │\n",
       "│ 7675      ┆ 2023-01-01 02:00:00 ┆ 16.6 ┆ 4.2   │\n",
       "│ 7675      ┆ 2023-01-01 03:00:00 ┆ 18.7 ┆ 4.1   │\n",
       "│ 7675      ┆ 2023-01-01 04:00:00 ┆ 15.1 ┆ 3.5   │\n",
       "│ …         ┆ …                   ┆ …    ┆ …     │\n",
       "│ 77709     ┆ 2023-01-23 15:00:00 ┆ 6.5  ┆ 2.8   │\n",
       "│ 77709     ┆ 2023-01-23 16:00:00 ┆ 6.1  ┆ 3.1   │\n",
       "│ 77709     ┆ 2023-01-23 17:00:00 ┆ 13.4 ┆ 6.7   │\n",
       "│ 77709     ┆ 2023-01-23 18:00:00 ┆ 15.5 ┆ 8.4   │\n",
       "│ 77709     ┆ 2023-01-23 19:00:00 ┆ 20.5 ┆ 10.4  │\n",
       "└───────────┴─────────────────────┴──────┴───────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_data_fact_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sensor_data_dim_df(raw_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    sensor_data_dim_df = (raw_df\n",
    "                    .filter([pl.col('lon').is_between(-3, -2),\n",
    "                        pl.col('lat').is_between(50, 52)])\n",
    "                        .select(['sensor_id', 'lat', 'lon'])\n",
    "                        .group_by('sensor_id')\n",
    "                        .agg([pl.col('lat').mean(),\n",
    "                            pl.col('lon').mean()])                \n",
    "                    ).collect()\n",
    "    \n",
    "\n",
    "    return sensor_data_dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 36\n",
      "Columns: 3\n",
      "$ sensor_id <i64> 33862, 67665, 66970, 34457, 7685, 70369, 78947, 17741, 48881, 69775\n",
      "$ lat       <f64> 51.436000000001265, 51.47199999999817, 51.46600000000033, 51.8505059400016, 51.474000000001205, 51.35599999999979, 51.472510399996764, 51.82200000000011, 51.4060000000018, 51.44999999999808\n",
      "$ lon       <f64> -2.742000000000117, -2.573999999999921, -2.587999999999987, -2.2450679499998865, -2.5760000000000205, -2.905999999999955, -2.5991219799998637, -2.26800000000002, -2.402000000000038, -2.51599999999994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sensor_data_dim.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect('data/new.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7fce7c50ae30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS raw_tbl;\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Table with name raw_tbl does not exist!\nDid you mean \"temp.information_schema.tables\"?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatalogException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43mCOPY raw_tbl FROM \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2023-12_sds011.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mCatalogException\u001b[0m: Catalog Error: Table with name raw_tbl does not exist!\nDid you mean \"temp.information_schema.tables\"?"
     ]
    }
   ],
   "source": [
    "con.sql(\"\"\"\n",
    "COPY raw_tbl FROM 'data/2023-12_sds011.csv'\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "t = duckdb.read_csv('data/2023-12_sds011.csv', \n",
    "                header=True,\n",
    "                sep=';',\n",
    "                dtype={\n",
    "                      'sensor_id': int,\n",
    "                      'sensor_type': str,\n",
    "                      'location': str,\n",
    "                      'lat': float,\n",
    "                      'lon': float,\n",
    "                      'timestamp': str,\n",
    "                      'P1': str,\n",
    "                      'durP1': str,\n",
    "                      'ratioP1': str,\n",
    "                      'P2': str,\n",
    "                      'durP2': str,\n",
    "                      'ratioP2': str,\n",
    "                  }, parallel=True).pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duckdb.duckdb.DuckDBPyRelation"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame constructor called with unsupported type 'DuckDBPyRelation' for the `data` parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18044/1175028592.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/python_projects/polars_playground/.venv/lib/python3.10/site-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, schema, schema_overrides, orient, infer_schema_length, nan_to_null)\u001b[0m\n\u001b[1;32m    423\u001b[0m             msg = (\n\u001b[1;32m    424\u001b[0m                 \u001b[0;34mf\"DataFrame constructor called with unsupported type {type(data).__name__!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;34m\" for the `data` parameter\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             )\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: DataFrame constructor called with unsupported type 'DuckDBPyRelation' for the `data` parameter"
     ]
    }
   ],
   "source": [
    "tp = pl.DataFrame(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConversionException",
     "evalue": "Conversion Error: CSV Error on Line: 1\nError when converting column \"sensor_id\".\nCould not convert string \"sensor_id;sensor_type;location;lat;lon;timestamp;P1;durP1;ratioP1;P2;durP2;ratioP2\" to 'INTEGER'\n\n  file=data/2023-12_sds011.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = \" (Auto-Detected)\n  new_line = \\n (Auto-Detected)\n  header = false (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  date_format =  (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding=0\n  sample_size=20480\n  ignore_errors=0\n  all_varchar=0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConversionException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43;03mCREATE TABLE raw_tbl(sensor_id INTEGER,\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43;03mlocation INTEGER,\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43;03mtimestamp VARCHAR,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43;03mlat FLOAT,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43;03mlon FLOAT,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43;03mP1 FLOAT,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43;03mdurP1 FLOAT,\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43;03mratioP1 FLOAT,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43;03mP2 FLOAT,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43;03mdurP2 FLOAT,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43;03mratioP2 FLOAT\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43;03m);\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43;03mCOPY raw_tbl FROM 'data/2023-12_sds011.csv' (AUTO_DETECT false);\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mConversionException\u001b[0m: Conversion Error: CSV Error on Line: 1\nError when converting column \"sensor_id\".\nCould not convert string \"sensor_id;sensor_type;location;lat;lon;timestamp;P1;durP1;ratioP1;P2;durP2;ratioP2\" to 'INTEGER'\n\n  file=data/2023-12_sds011.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = \" (Auto-Detected)\n  new_line = \\n (Auto-Detected)\n  header = false (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  date_format =  (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding=0\n  sample_size=20480\n  ignore_errors=0\n  all_varchar=0\n"
     ]
    }
   ],
   "source": [
    "con.execute(\n",
    "\"\"\"\n",
    "CREATE TABLE raw_tbl(sensor_id INTEGER,\n",
    "location INTEGER,\n",
    "timestamp VARCHAR,\n",
    "lat FLOAT,\n",
    "lon FLOAT,\n",
    "P1 FLOAT,\n",
    "durP1 FLOAT,\n",
    "ratioP1 FLOAT,\n",
    "P2 FLOAT,\n",
    "durP2 FLOAT,\n",
    "ratioP2 FLOAT\n",
    ");\n",
    "COPY raw_tbl FROM 'data/2023-12_sds011.csv' (AUTO_DETECT false);\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "con.execute(\n",
    "\"\"\"\n",
    "CREATE TABLE all_tbl(sensor_id INTEGER, location INTEGER, timestamp VARCHAR, lat FLOAT, lon FLOAT, P1 FLOAT, P2 FLOAT);\n",
    "COPY raw_tbl FROM 'data/sds011_pldf.csv' (AUTO_DETECT true);\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the read_csv constructor within the sql function is very slow, possibly due to type conversion during read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.sql(\n",
    "\"\"\"\n",
    "\n",
    "SELECT sensor_id, location, timestamp, lat, lon, P1, P2 \n",
    "FROM 'data/sds011_pldf.csv'\n",
    "WHERE (lat > 51 AND lat < 52) AND (lon < -2 AND lon > -3)\n",
    "\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to polars DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pldf = df.pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 574057\n",
      "Columns: 7\n",
      "$ sensor_id          <i64> 24147, 10491, 48881, 7685, 78664, 77022, 66667, 78947, 56255, 34457\n",
      "$ location           <i64> 12309, 5293, 57063, 3885, 67981, 65952, 57205, 72966, 57229, 20702\n",
      "$ timestamp <datetime[μs]> 2023-12-01 00:00:05, 2023-12-01 00:00:07, 2023-12-01 00:00:10, 2023-12-01 00:00:14, 2023-12-01 00:00:14, 2023-12-01 00:00:17, 2023-12-01 00:00:27, 2023-12-01 00:00:33, 2023-12-01 00:00:41, 2023-12-01 00:00:56\n",
      "$ lat                <f64> 51.45, 51.464, 51.406, 51.474, 51.022, 51.44, 51.438, 51.4725104, 51.432, 51.85050594\n",
      "$ lon                <f64> -2.624, -2.566, -2.402, -2.576, -2.87, -2.054, -2.006, -2.59912198, -2.598, -2.24506795\n",
      "$ P1                 <f64> 25.03, 18.03, 14.25, 0.8, 3.78, 24.17, 17.5, 2.4, 35.58, 12.95\n",
      "$ P2                 <f64> 9.87, 11.57, 7.82, 0.8, 3.03, 9.63, 10.73, 1.6, 20.0, 10.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pldf.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurands are imported as strings, probably due to anomalous data in these fields. Convert to hourly mean data using group by dynamic after sorting first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (23_887, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sensor_id</th><th>lat</th><th>lon</th><th>date</th><th>PM10_mean</th><th>PM2.5_mean</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>datetime[μs]</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 00:00:00</td><td>3.8996</td><td>1.6172</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 01:00:00</td><td>0.605833</td><td>0.554583</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 02:00:00</td><td>0.53</td><td>0.488333</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 03:00:00</td><td>0.3364</td><td>0.3364</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 04:00:00</td><td>0.348333</td><td>0.348333</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 05:00:00</td><td>0.516667</td><td>0.359583</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 06:00:00</td><td>0.404</td><td>0.396</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 07:00:00</td><td>1.856667</td><td>0.9075</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 08:00:00</td><td>1.062083</td><td>0.846667</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 09:00:00</td><td>1.4428</td><td>0.728</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 10:00:00</td><td>1.021667</td><td>0.599583</td></tr><tr><td>7685</td><td>51.474</td><td>-2.576</td><td>2023-12-01 11:00:00</td><td>0.952083</td><td>0.748333</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 12:00:00</td><td>11.272917</td><td>2.677917</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 13:00:00</td><td>15.2472</td><td>3.0084</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 14:00:00</td><td>10.445833</td><td>2.260833</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 15:00:00</td><td>9.5812</td><td>2.3964</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 16:00:00</td><td>8.254167</td><td>2.615417</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 17:00:00</td><td>8.7312</td><td>2.4164</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 18:00:00</td><td>14.2144</td><td>3.8872</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 19:00:00</td><td>13.702917</td><td>3.76</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 20:00:00</td><td>12.2276</td><td>3.5332</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 21:00:00</td><td>11.8124</td><td>3.514</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 22:00:00</td><td>10.258333</td><td>3.487917</td></tr><tr><td>80332</td><td>51.864</td><td>-2.246</td><td>2023-12-31 23:00:00</td><td>11.4168</td><td>4.3588</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (23_887, 6)\n",
       "┌───────────┬────────┬────────┬─────────────────────┬───────────┬────────────┐\n",
       "│ sensor_id ┆ lat    ┆ lon    ┆ date                ┆ PM10_mean ┆ PM2.5_mean │\n",
       "│ ---       ┆ ---    ┆ ---    ┆ ---                 ┆ ---       ┆ ---        │\n",
       "│ i64       ┆ f64    ┆ f64    ┆ datetime[μs]        ┆ f64       ┆ f64        │\n",
       "╞═══════════╪════════╪════════╪═════════════════════╪═══════════╪════════════╡\n",
       "│ 7685      ┆ 51.474 ┆ -2.576 ┆ 2023-12-01 00:00:00 ┆ 3.8996    ┆ 1.6172     │\n",
       "│ 7685      ┆ 51.474 ┆ -2.576 ┆ 2023-12-01 01:00:00 ┆ 0.605833  ┆ 0.554583   │\n",
       "│ 7685      ┆ 51.474 ┆ -2.576 ┆ 2023-12-01 02:00:00 ┆ 0.53      ┆ 0.488333   │\n",
       "│ 7685      ┆ 51.474 ┆ -2.576 ┆ 2023-12-01 03:00:00 ┆ 0.3364    ┆ 0.3364     │\n",
       "│ …         ┆ …      ┆ …      ┆ …                   ┆ …         ┆ …          │\n",
       "│ 80332     ┆ 51.864 ┆ -2.246 ┆ 2023-12-31 20:00:00 ┆ 12.2276   ┆ 3.5332     │\n",
       "│ 80332     ┆ 51.864 ┆ -2.246 ┆ 2023-12-31 21:00:00 ┆ 11.8124   ┆ 3.514      │\n",
       "│ 80332     ┆ 51.864 ┆ -2.246 ┆ 2023-12-31 22:00:00 ┆ 10.258333 ┆ 3.487917   │\n",
       "│ 80332     ┆ 51.864 ┆ -2.246 ┆ 2023-12-31 23:00:00 ┆ 11.4168   ┆ 4.3588     │\n",
       "└───────────┴────────┴────────┴─────────────────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    pldf\n",
    "    .with_columns(pl.col(pl.Utf8).cast(pl.Float64))\n",
    "    .sort('sensor_id', 'timestamp')\n",
    "    .group_by_dynamic(pl.col('timestamp').alias('date'), every= '1h', by= ['sensor_id', 'lat', 'lon'])\n",
    "    .agg(pl.col('P1').mean().alias('PM10_mean'),\n",
    "         pl.col('P2').mean().alias('PM2.5_mean'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.dataframe.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pldf.write_csv('data/sds011_pldf.csv')\n",
    "type(pldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_bristol = pl.read_csv('data/sds011_pldf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.dataframe.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sds_bristol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (574_057, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sensor_id</th><th>location</th><th>timestamp</th><th>lat</th><th>lon</th><th>P1</th><th>P2</th></tr><tr><td>i64</td><td>i64</td><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>24147</td><td>12309</td><td>2023-12-01 00:00:05</td><td>51.45</td><td>-2.624</td><td>25.03</td><td>9.87</td></tr><tr><td>10491</td><td>5293</td><td>2023-12-01 00:00:07</td><td>51.464</td><td>-2.566</td><td>18.03</td><td>11.57</td></tr><tr><td>48881</td><td>57063</td><td>2023-12-01 00:00:10</td><td>51.406</td><td>-2.402</td><td>14.25</td><td>7.82</td></tr><tr><td>7685</td><td>3885</td><td>2023-12-01 00:00:14</td><td>51.474</td><td>-2.576</td><td>0.8</td><td>0.8</td></tr><tr><td>78664</td><td>67981</td><td>2023-12-01 00:00:14</td><td>51.022</td><td>-2.87</td><td>3.78</td><td>3.03</td></tr><tr><td>77022</td><td>65952</td><td>2023-12-01 00:00:17</td><td>51.44</td><td>-2.054</td><td>24.17</td><td>9.63</td></tr><tr><td>66667</td><td>57205</td><td>2023-12-01 00:00:27</td><td>51.438</td><td>-2.006</td><td>17.5</td><td>10.73</td></tr><tr><td>78947</td><td>72966</td><td>2023-12-01 00:00:33</td><td>51.47251</td><td>-2.599122</td><td>2.4</td><td>1.6</td></tr><tr><td>56255</td><td>57229</td><td>2023-12-01 00:00:41</td><td>51.432</td><td>-2.598</td><td>35.58</td><td>20.0</td></tr><tr><td>34457</td><td>20702</td><td>2023-12-01 00:00:56</td><td>51.850506</td><td>-2.245068</td><td>12.95</td><td>10.57</td></tr><tr><td>26044</td><td>13819</td><td>2023-12-01 00:00:57</td><td>51.442745</td><td>-2.593819</td><td>25.35</td><td>15.6</td></tr><tr><td>48987</td><td>34799</td><td>2023-12-01 00:01:03</td><td>51.44</td><td>-2.534</td><td>19.8</td><td>8.82</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>48881</td><td>57063</td><td>2023-12-31 23:58:35</td><td>51.406</td><td>-2.402</td><td>14.4</td><td>2.53</td></tr><tr><td>26044</td><td>13819</td><td>2023-12-31 23:58:42</td><td>51.442745</td><td>-2.593819</td><td>16.4</td><td>3.0</td></tr><tr><td>64397</td><td>50718</td><td>2023-12-31 23:58:45</td><td>51.880926</td><td>-2.054953</td><td>7.43</td><td>1.58</td></tr><tr><td>68597</td><td>55568</td><td>2023-12-31 23:59:03</td><td>51.037457</td><td>-2.829591</td><td>15.37</td><td>3.53</td></tr><tr><td>39950</td><td>25629</td><td>2023-12-31 23:59:05</td><td>51.444</td><td>-2.606</td><td>0.0</td><td>0.0</td></tr><tr><td>80332</td><td>69652</td><td>2023-12-31 23:59:08</td><td>51.864</td><td>-2.246</td><td>10.13</td><td>4.22</td></tr><tr><td>78947</td><td>72966</td><td>2023-12-31 23:59:09</td><td>51.47251</td><td>-2.599122</td><td>7.6</td><td>1.75</td></tr><tr><td>70369</td><td>57790</td><td>2023-12-31 23:59:09</td><td>51.356</td><td>-2.906</td><td>8.63</td><td>0.9</td></tr><tr><td>40575</td><td>26284</td><td>2023-12-31 23:59:14</td><td>51.71896</td><td>-2.184421</td><td>8.7</td><td>1.9</td></tr><tr><td>33862</td><td>20158</td><td>2023-12-31 23:59:16</td><td>51.436</td><td>-2.742</td><td>12.32</td><td>3.08</td></tr><tr><td>66970</td><td>53901</td><td>2023-12-31 23:59:50</td><td>51.466</td><td>-2.588</td><td>13.82</td><td>2.0</td></tr><tr><td>66700</td><td>73540</td><td>2023-12-31 23:59:58</td><td>51.02816</td><td>-2.86914</td><td>13.38</td><td>3.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (574_057, 7)\n",
       "┌───────────┬──────────┬─────────────────────┬──────────┬───────────┬───────┬───────┐\n",
       "│ sensor_id ┆ location ┆ timestamp           ┆ lat      ┆ lon       ┆ P1    ┆ P2    │\n",
       "│ ---       ┆ ---      ┆ ---                 ┆ ---      ┆ ---       ┆ ---   ┆ ---   │\n",
       "│ i64       ┆ i64      ┆ datetime[μs]        ┆ f64      ┆ f64       ┆ f64   ┆ f64   │\n",
       "╞═══════════╪══════════╪═════════════════════╪══════════╪═══════════╪═══════╪═══════╡\n",
       "│ 24147     ┆ 12309    ┆ 2023-12-01 00:00:05 ┆ 51.45    ┆ -2.624    ┆ 25.03 ┆ 9.87  │\n",
       "│ 10491     ┆ 5293     ┆ 2023-12-01 00:00:07 ┆ 51.464   ┆ -2.566    ┆ 18.03 ┆ 11.57 │\n",
       "│ 48881     ┆ 57063    ┆ 2023-12-01 00:00:10 ┆ 51.406   ┆ -2.402    ┆ 14.25 ┆ 7.82  │\n",
       "│ 7685      ┆ 3885     ┆ 2023-12-01 00:00:14 ┆ 51.474   ┆ -2.576    ┆ 0.8   ┆ 0.8   │\n",
       "│ …         ┆ …        ┆ …                   ┆ …        ┆ …         ┆ …     ┆ …     │\n",
       "│ 40575     ┆ 26284    ┆ 2023-12-31 23:59:14 ┆ 51.71896 ┆ -2.184421 ┆ 8.7   ┆ 1.9   │\n",
       "│ 33862     ┆ 20158    ┆ 2023-12-31 23:59:16 ┆ 51.436   ┆ -2.742    ┆ 12.32 ┆ 3.08  │\n",
       "│ 66970     ┆ 53901    ┆ 2023-12-31 23:59:50 ┆ 51.466   ┆ -2.588    ┆ 13.82 ┆ 2.0   │\n",
       "│ 66700     ┆ 73540    ┆ 2023-12-31 23:59:58 ┆ 51.02816 ┆ -2.86914  ┆ 13.38 ┆ 3.5   │\n",
       "└───────────┴──────────┴─────────────────────┴──────────┴───────────┴───────┴───────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sds_bristol\n",
    " .with_columns(pl.col(pl.Utf8).cast(pl.Datetime))\n",
    " \n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = (\n",
    "    pldf\n",
    "    .with_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # columns = {\n",
    "    # 'sensor_id': 'BIGINT',\n",
    "    # 'location': 'BIGINT',\n",
    "    # 'timestamp': 'TIMESTAMP',\n",
    "    # 'lat': 'REAL',\n",
    "    # 'lon': 'REAL',\n",
    "    # 'P1':'REAL',\n",
    "    # 'P2':'REAL'\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 574057\n",
      "Columns: 7\n",
      "$ sensor_id          <i64> 24147, 10491, 48881, 7685, 78664, 77022, 66667, 78947, 56255, 34457\n",
      "$ location           <i64> 12309, 5293, 57063, 3885, 67981, 65952, 57205, 72966, 57229, 20702\n",
      "$ timestamp <datetime[μs]> 2023-12-01 00:00:05, 2023-12-01 00:00:07, 2023-12-01 00:00:10, 2023-12-01 00:00:14, 2023-12-01 00:00:14, 2023-12-01 00:00:17, 2023-12-01 00:00:27, 2023-12-01 00:00:33, 2023-12-01 00:00:41, 2023-12-01 00:00:56\n",
      "$ lat                <f64> 51.45, 51.464, 51.406, 51.474, 51.022, 51.44, 51.438, 51.4725104, 51.432, 51.85050594\n",
      "$ lon                <f64> -2.624, -2.566, -2.402, -2.576, -2.87, -2.054, -2.006, -2.59912198, -2.598, -2.24506795\n",
      "$ P1                 <str> '25.03', '18.03', '14.25', '0.80', '3.78', '24.17', '17.50', '2.40', '35.58', '12.95'\n",
      "$ P2                 <str> '9.87', '11.57', '7.82', '0.80', '3.03', '9.63', '10.73', '1.60', '20.00', '10.57'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pldf.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_qry = (pl.scan_csv(source='data/2023-12_sds011.csv',\n",
    "                  n_rows= 100000000,\n",
    "                  null_values = [' ', 'unavailable', 'unknown', 'b'],\n",
    "                  separator=';')\n",
    "                  .select(pl.col(['sensor_id', 'location', 'lat', 'lon', 'timestamp', 'P1', 'P2']))\n",
    "                #   .with_columns(pl.col(['lat', 'lon']).cast(pl.Float64),\n",
    "                #                 pl.col('timestamp').str.to_datetime(format = '%Y-%m-%dT%H:%M:%S'))\n",
    "                #    .filter([pl.col('lat').is_between(51, 52), pl.col('lon').is_between(-3, -1.9)])\n",
    "                #    .rename({\n",
    "                #        'P1':'PM10',\n",
    "                #        'P2':'PM2.5',\n",
    "                #        'timestamp':'datetime'\n",
    "                #    })\n",
    "                \n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = (pl.read_csv_batched(\n",
    "    'data/2023-12_sds011.csv',\n",
    "    null_values = [' ', 'unavailable', 'unknown', 'b'],\n",
    "    columns = ['sensor_id', 'location', 'lat', 'lon', 'timestamp', 'P1', 'P2'],\n",
    "    separator=';',\n",
    "    ignore_errors = True,\n",
    "    # dtypes = {\n",
    "    #                   'sensor_id': pl.Int64,\n",
    "    #                   'location': pl.Utf8,\n",
    "    #                   'lat':pl.Float64,\n",
    "    #                   'lon':pl.Float64,\n",
    "    #                   'timestamp':pl.Datetime,\n",
    "    #                   'P1':pl.Float64,\n",
    "    #                   'P2':pl.Float64\n",
    "    #               }\n",
    "    # try_parse_dates = True\n",
    "    )\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = reader.next_batches(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "while batches:\n",
    "    df_current_batches = pl.concat(batches)\n",
    "    df_list.append(df_current_batches)\n",
    "    batches = reader.next_batches(100)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 50327703\n",
      "Columns: 7\n",
      "$ sensor_id <i64> 33756, 35558, 53080, 64777, 75993, 39874, 8887, 30876, 23578, 20020\n",
      "$ location  <i64> 62507, 21661, 51117, 51212, 64680, 73346, 4480, 17582, 11967, 10171\n",
      "$ lat       <f64> 51.7285344, 50.794, 52.710001, 42.4855289, 53.8, 52.53073404, 52.37, 48.15869432, 50.852, 42.694\n",
      "$ lon       <f64> 9.01158874, -1.066, 6.851716, 23.40718567, 9.988, 13.17634106, 9.748, 11.55006838, 4.4, 23.318\n",
      "$ timestamp <str> '2023-12-04T19:05:16', '2023-12-04T19:05:16', '2023-12-04T19:05:16', '2023-12-04T19:05:16', '2023-12-04T19:05:16', '2023-12-04T19:05:16', '2023-12-04T19:05:16', '2023-12-04T19:05:16', '2023-12-04T19:05:16', '2023-12-04T19:05:16'\n",
      "$ P1        <f64> 0.55, 0.6, 10.15, 10.5, 10.63, 10.73, 10.8, 11.3, 11.88, 1195.72\n",
      "$ P2        <f64> 0.32, 0.6, 4.25, 4.82, 4.43, 4.63, 7.68, 5.47, 6.45, 999.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df = lazy_qry.collect() #crashes kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 27954\n",
      "Columns: 7\n",
      "$ sensor_id          <i64> 24147, 10491, 48881, 7685, 78664, 77022, 66667, 78947, 56255, 34457\n",
      "$ location           <i64> 12309, 5293, 57063, 3885, 67981, 65952, 57205, 72966, 57229, 20702\n",
      "$ lat                <f64> 51.45, 51.464, 51.406, 51.474, 51.022, 51.44, 51.438, 51.4725104, 51.432, 51.85050594\n",
      "$ lon                <f64> -2.624, -2.566, -2.402, -2.576, -2.87, -2.054, -2.006, -2.59912198, -2.598, -2.24506795\n",
      "$ datetime  <datetime[μs]> 2023-12-01 00:00:05, 2023-12-01 00:00:07, 2023-12-01 00:00:10, 2023-12-01 00:00:14, 2023-12-01 00:00:14, 2023-12-01 00:00:17, 2023-12-01 00:00:27, 2023-12-01 00:00:33, 2023-12-01 00:00:41, 2023-12-01 00:00:56\n",
      "$ PM10               <f64> 25.03, 18.03, 14.25, 0.8, 3.78, 24.17, 17.5, 2.4, 35.58, 12.95\n",
      "$ PM2.5              <f64> 9.87, 11.57, 7.82, 0.8, 3.03, 9.63, 10.73, 1.6, 20.0, 10.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " schema = {\n",
    "                      'sensor_id': pl.Int64,\n",
    "                      'location': pl.Utf8,\n",
    "                      'lat':pl.Float64,\n",
    "                      'lon':pl.Float64,\n",
    "                      'timestamp':pl.Datetime,\n",
    "                      'P1':pl.Float64,\n",
    "                      'P2':pl.Float64\n",
    "                  }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
